services:
  ap:
    build:
      context: .
      network: host
      args:
        http_proxy: "http://127.0.0.1:3128"
        https_proxy: "http://127.0.0.1:3128"
        no_proxy: "${no_proxy}"

        TORCH_INDEX_URL: "https://download.pytorch.org/whl/nightly/cpu"
        TORCH_VERSION: "2.11.0.dev20260121+cpu"
        PYTHON_VERSION: "3.11"

    image: ap-llama3-cpu:torch-2.11.0.dev20260121
    network_mode: host
    working_dir: /workspace
    shm_size: "8g"

    environment:
      http_proxy: "http://127.0.0.1:3128"
      https_proxy: "http://127.0.0.1:3128"
      no_proxy: "${no_proxy}"

      HF_HOME: /cache/huggingface
      TRANSFORMERS_CACHE: /cache/huggingface/transformers
      HF_HUB_DISABLE_TELEMETRY: "1"
      TOKENIZERS_PARALLELISM: "false"
      PYTHONUNBUFFERED: "1"

    volumes:
      - "${PWD}:/workspace:rw"
      - "${HOME}/models:/models:ro"
      - "${HOME}/.cache/ap_hf:/cache:rw"

    command: ["/bin/bash"]
